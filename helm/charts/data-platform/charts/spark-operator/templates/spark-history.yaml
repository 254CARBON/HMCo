# Spark History Server for monitoring Spark applications
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-history-server
  namespace: data-platform
  labels:
    app: spark-history-server
    component: compute
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-history-server
  template:
    metadata:
      labels:
        app: spark-history-server
        component: compute
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        seccompProfile:
          type: RuntimeDefault
      imagePullSecrets: []
      containers:
      - name: spark-history-server
        image: apache/spark:3.5.0
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
        ports:
          - containerPort: 18080
            name: history-ui
          - containerPort: 18081
            name: history-admin
        command:
        - /opt/spark/bin/spark-class
        - org.apache.spark.deploy.history.HistoryServer
        env:
        - name: SPARK_HISTORY_OPTS
          value: "-Dspark.history.fs.logDirectory=file:/opt/spark/work -Dspark.history.fs.cleaner.enabled=true -Dspark.history.fs.cleaner.maxAge=7d -Dspark.history.ui.port=18080 -Dspark.history.admin.port=18081"
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: minio-secret
              key: access-key
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: minio-secret
              key: secret-key
        - name: S3_ENDPOINT
          value: "http://minio-service:9000"
        volumeMounts:
        - name: spark-logs
          mountPath: /opt/spark/work
        - name: spark-conf
          mountPath: /opt/spark/conf
        resources:
          limits:
            memory: "2Gi"
            cpu: "1000m"
          requests:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /
            port: 18080
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /
            port: 18080
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
      volumes:
      - name: spark-logs
        persistentVolumeClaim:
          claimName: spark-logs-pvc
      - name: spark-conf
        configMap:
          name: spark-history-conf
---
# Spark History Server Service
apiVersion: v1
kind: Service
metadata:
  name: spark-history-server
  namespace: data-platform
  labels:
    app: spark-history-server
spec:
  ports:
  - port: 18080
    targetPort: 18080
    name: history-ui
  selector:
    app: spark-history-server
  type: ClusterIP

---
# Ingress for Spark History Server UI
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: spark-history-server
  namespace: data-platform
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rewrite-target: /
    portal.254carbon.com/service-id: "spark-history"
    portal.254carbon.com/service-name: "Spark History Server"
    portal.254carbon.com/service-category: "data-platform"
    portal.254carbon.com/service-description: "Spark job history and diagnostics"
    portal.254carbon.com/service-icon: "ðŸ”¥"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - spark-history.254carbon.com
    secretName: spark-history-tls
  rules:
  - host: spark-history.254carbon.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: spark-history-server
            port:
              number: 18080
---
# Persistent Volume Claim for Spark logs
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: spark-logs-pvc
  namespace: data-platform
  labels:
    app: spark-history-server
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: local-storage-standard
---
# ConfigMap for Spark History Server configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-history-conf
  namespace: data-platform
  labels:
    app: spark-history-server
data:
  spark-defaults.conf: |
    # Spark configuration for history server
    spark.history.fs.logDirectory file:/opt/spark/work
    spark.history.fs.cleaner.enabled true
    spark.history.fs.cleaner.maxAge 7d
    spark.history.ui.port 18080
    spark.history.admin.port 18081

    # Spark SQL and general settings
    spark.sql.adaptive.enabled true
    spark.sql.adaptive.coalescePartitions.enabled true
    spark.serializer org.apache.spark.serializer.KryoSerializer

  log4j.properties: |
    # Logging configuration
    log4j.rootCategory=INFO, console
    log4j.appender.console=org.apache.log4j.ConsoleAppender
    log4j.appender.console.layout=org.apache.log4j.PatternLayout
    log4j.appender.console.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n
