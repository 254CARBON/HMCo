# AlertManager deployment for alert aggregation and routing
# Routes alerts to appropriate channels based on severity and labels

---
# ConfigMap for AlertManager configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
  labels:
    app: alertmanager
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
      slack_api_url: ''  # Set your Slack webhook URL here
      pagerduty_url: ''  # Optional: PagerDuty integration
    
    # Inhibition rules prevent alerts from being sent if others are already sent
    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'namespace', 'instance']
    - source_match:
        severity: 'warning'
      target_match:
        severity: 'info'
      equal: ['alertname', 'namespace', 'instance']
    
    # Alert routing configuration
    route:
      receiver: 'default'
      group_by: ['alertname', 'cluster', 'service', 'namespace']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      routes:
      # SLO and synthetic canary alerts
      - match_re:
          slo: '.+'
        receiver: 'slo-alerts'
        continue: true
      # Critical alerts
      - match:
          severity: critical
        receiver: 'critical-alerts'
        group_wait: 10s
        group_interval: 2m
        repeat_interval: 1h
        continue: true
      # Storage alerts
      - match:
          alertname: 'StorageCapacityWarning|StorageCapacityCritical|PersistentVolumeError'
        receiver: 'storage-alerts'
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 6h
      # Database alerts
      - match:
          alertname: 'PostgreSQLDown|PostgreSQLTooManyConnections|MySQLDown'
        receiver: 'database-alerts'
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 6h
      # Pod restart alerts
      - match:
          alertname: 'PodRestartingTooOften'
        receiver: 'pod-alerts'
        group_wait: 2m
        group_interval: 10m
        repeat_interval: 12h
    
    # Receivers (notification destinations)
    receivers:
    - name: 'default'
      # Default receiver (add email if needed)
    
    - name: 'critical-alerts'
      # Critical alerts - example with email
      email_configs:
      - to: 'ops-team@example.com'
        from: 'alertmanager@example.com'
        smarthost: 'smtp.example.com:587'
        auth_username: 'alertmanager@example.com'
        auth_password: ''  # Use secret injection instead
        headers:
          Subject: 'CRITICAL: {{`{{ .GroupLabels.alertname }}`}}'
      # Optional: Slack for critical
      slack_configs:
      - channel: '#critical-alerts'
        title: 'CRITICAL ALERT'
        text: '{{`{{ range .Alerts }}{{ .Annotations.description }}{{ end }}`}}'
    
    - name: 'storage-alerts'
      slack_configs:
      - channel: '#storage-alerts'
        title: 'Storage Issue'

    - name: 'slo-alerts'
      slack_configs:
      - channel: '#slo-alerts'
        title: 'SLO Alert'
        text: '{{`{{ range .Alerts }}{{ .Annotations.summary }} â€” {{ .Annotations.description }}{{ "\\n" }}{{ end }}`}}'

    - name: 'database-alerts'
      slack_configs:
      - channel: '#database-alerts'
        title: 'Database Issue'
    
    - name: 'pod-alerts'
      slack_configs:
      - channel: '#pod-alerts'
        title: 'Pod Restart Alert'

---
# AlertManager Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: monitoring
  labels:
    app: alertmanager
spec:
  replicas: 2
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - alertmanager
              topologyKey: kubernetes.io/hostname
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.25.0
        args:
        - '--config.file=/etc/alertmanager/config.yml'
        - '--storage.path=/alertmanager'
        - '--log.level=info'
        ports:
        - containerPort: 9093
          name: http
        volumeMounts:
        - name: config
          mountPath: /etc/alertmanager
        - name: storage
          mountPath: /alertmanager
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9093
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9093
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: config
        configMap:
          name: alertmanager-config
      - name: storage
        emptyDir: {}

---
# AlertManager Service
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: monitoring
  labels:
    app: alertmanager
spec:
  type: ClusterIP
  ports:
  - port: 9093
    targetPort: 9093
    name: http
  selector:
    app: alertmanager

---
# AlertManager Ingress (for web UI access)
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: alertmanager-ingress
  namespace: monitoring
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "selfsigned"
    # Cloudflare Access SSO
    nginx.ingress.kubernetes.io/auth-url: "https://qagi.cloudflareaccess.com/cdn-cgi/access/authorize"
    nginx.ingress.kubernetes.io/auth-signin: "https://qagi.cloudflareaccess.com/cdn-cgi/access/login?redirect_url=$escaped_request_uri"
    nginx.ingress.kubernetes.io/auth-response-headers: "cf-access-jwt-assertion"
    nginx.ingress.kubernetes.io/configuration-snippet: |
      auth_request_set $cf_email $upstream_http_cf_access_authenticated_user_email;
      auth_request_set $cf_groups $upstream_http_cf_access_groups;
      proxy_set_header X-WEBAUTH-USER $cf_email;
      proxy_set_header X-WEBAUTH-EMAIL $cf_email;
      proxy_set_header X-WEBAUTH-GROUPS $cf_groups;
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - alertmanager.254carbon.com
        - alertmanager.local
      secretName: alertmanager-tls
  rules:
    - host: alertmanager.254carbon.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: alertmanager
                port:
                  number: 9093
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: alertmanager
                port:
                  number: 9093
