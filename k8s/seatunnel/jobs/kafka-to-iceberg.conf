# SeaTunnel Job: Kafka to Iceberg
# Streams events from Kafka topic to Iceberg table

env {
  execution.parallelism = 2
  job.mode = "STREAMING"
  checkpoint.interval = 30000
}

source {
  Kafka {
    bootstrap.servers = "kafka-service:9092"
    topic = "events"
    consumer.group = "seatunnel-iceberg-group"
    result_table_name = "kafka_events"
    format = "json"
    
    schema = {
      fields {
        event_id = "bigint"
        event_type = "string"
        event_data = "string"
        event_timestamp = "string"
        user_id = "bigint"
      }
    }
  }
}

sink {
  Iceberg {
    catalog_name = "rest"
    catalog_type = "rest"
    warehouse = "s3://iceberg-warehouse/"
    uri = "http://iceberg-rest-catalog:8181"
    database = "raw"
    table = "events"
    
    # S3/MinIO configuration
    s3.access-key-id = "minioadmin"
    s3.secret-access-key = "minioadmin123"
    s3.region = "us-east-1"
    s3.endpoint = "http://minio-service:9000"
    
    # Iceberg table configuration
    partition_by = ["event_type", "year(event_timestamp)"]
    
    # Write options
    write_format = "parquet"
    compression_codec = "snappy"
    
    # Schema
    schema = {
      fields {
        event_id = "bigint"
        event_type = "string"
        event_data = "string"
        event_timestamp = "timestamp"
        user_id = "bigint"
      }
    }
  }
}
