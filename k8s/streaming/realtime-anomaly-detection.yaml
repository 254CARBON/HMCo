---
# Real-time Anomaly Detection for Commodity Prices
# Uses streaming data and ML models for instant anomaly alerts

apiVersion: apps/v1
kind: Deployment
metadata:
  name: anomaly-detector
  namespace: data-platform
  labels:
    app: anomaly-detector
    component: ml
spec:
  replicas: 2
  selector:
    matchLabels:
      app: anomaly-detector
  template:
    metadata:
      labels:
        app: anomaly-detector
        component: ml
    spec:
      containers:
      - name: detector
        image: python:3.11-slim
        command:
        - /bin/bash
        - -c
        - |
          pip install --quiet kafka-python scikit-learn numpy pandas redis
          
          python << 'EOF'
          import json
          import numpy as np
          from kafka import KafkaConsumer, KafkaProducer
          from sklearn.ensemble import IsolationForest
          import redis
          from datetime import datetime
          
          # Initialize
          consumer = KafkaConsumer(
              'commodity-prices',
              bootstrap_servers='kafka-service:9092',
              value_deserializer=lambda m: json.loads(m.decode('utf-8')),
              group_id='anomaly-detector'
          )
          
          producer = KafkaProducer(
              bootstrap_servers='kafka-service:9092',
              value_serializer=lambda v: json.dumps(v).encode('utf-8')
          )
          
          redis_client = redis.Redis(host='redis-service', port=6379, decode_responses=True)
          
          # Load or train model
          model = IsolationForest(contamination=0.05, random_state=42)
          
          print("Real-time anomaly detector started...")
          
          # Store recent prices for each commodity
          price_windows = {}
          
          for message in consumer:
              try:
                  data = message.value
                  commodity = data.get('commodity')
                  price = data.get('price')
                  timestamp = data.get('timestamp', datetime.now().isoformat())
                  
                  if commodity not in price_windows:
                      price_windows[commodity] = []
                  
                  # Keep last 100 prices
                  price_windows[commodity].append(price)
                  if len(price_windows[commodity]) > 100:
                      price_windows[commodity].pop(0)
                  
                  # Need at least 30 samples to detect anomalies
                  if len(price_windows[commodity]) >= 30:
                      # Prepare features
                      prices = np.array(price_windows[commodity]).reshape(-1, 1)
                      
                      # Detect anomaly
                      model.fit(prices)
                      prediction = model.predict([[price]])
                      
                      if prediction[0] == -1:  # Anomaly detected
                          anomaly_event = {
                              'event_type': 'PRICE_ANOMALY_DETECTED',
                              'commodity': commodity,
                              'price': price,
                              'timestamp': timestamp,
                              'severity': 'high',
                              'message': f'Unusual price detected for {commodity}: ${price}'
                          }
                          
                          # Publish anomaly event
                          producer.send('data-quality-events', value=anomaly_event)
                          
                          # Cache in Redis
                          redis_client.setex(
                              f'anomaly:{commodity}:{timestamp}',
                              3600,  # 1 hour TTL
                              json.dumps(anomaly_event)
                          )
                          
                          print(f"ðŸš¨ ANOMALY: {commodity} price ${price} at {timestamp}")
                      else:
                          print(f"âœ“ Normal: {commodity} ${price}")
              
              except Exception as e:
                  print(f"Error processing message: {e}")
          EOF
        env:
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: kafka-service:9092
        - name: REDIS_HOST
          value: redis-service
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 4Gi

---
apiVersion: v1
kind: Service
metadata:
  name: anomaly-detector
  namespace: data-platform
  labels:
    app: anomaly-detector
spec:
  selector:
    app: anomaly-detector
  ports:
  - port: 8080
    targetPort: 8080
    name: metrics
  type: ClusterIP

---
# Anomaly Alert Rules
apiVersion: v1
kind: ConfigMap
metadata:
  name: anomaly-detection-alerts
  namespace: monitoring
data:
  anomaly-rules.yaml: |
    groups:
    - name: anomaly_detection
      interval: 30s
      rules:
      - alert: PriceAnomalyDetected
        expr: rate(anomaly_events_total[5m]) > 0
        for: 1m
        labels:
          severity: warning
          component: anomaly-detection
        annotations:
          summary: "Price anomaly detected"
          description: "Unusual price pattern detected in commodity data"
      
      - alert: AnomalyDetectorDown
        expr: up{job="anomaly-detector"} == 0
        for: 5m
        labels:
          severity: critical
          component: anomaly-detection
        annotations:
          summary: "Anomaly detector is down"
          description: "Real-time anomaly detection service is not responding"
      
      - alert: HighAnomalyRate
        expr: rate(anomaly_events_total[1h]) > 10
        for: 15m
        labels:
          severity: warning
          component: anomaly-detection
        annotations:
          summary: "High rate of anomalies detected"
          description: "More than 10 anomalies per hour detected"


