# Prometheus Alert Rules for Streaming Infrastructure
---
apiVersion: v1
kind: PrometheusRule
metadata:
  name: streaming-alerts
  namespace: monitoring
  labels:
    app: streaming
    release: kube-prometheus-stack
spec:
  groups:
  - name: kafka-connect-alerts
    interval: 30s
    rules:
    - alert: KafkaConnectConnectorFailed
      expr: kafka_connect_connector_status{state="FAILED"} > 0
      for: 2m
      labels:
        severity: critical
        component: kafka-connect
      annotations:
        summary: "Kafka Connect connector {{ $labels.connector }} failed"
        description: "Connector {{ $labels.connector }} in namespace {{ $labels.namespace }} is in FAILED state"
    
    - alert: KafkaConnectHighTaskFailureRate
      expr: rate(kafka_connect_connector_task_status{state="FAILED"}[5m]) > 0.1
      for: 5m
      labels:
        severity: warning
        component: kafka-connect
      annotations:
        summary: "High task failure rate for connector {{ $labels.connector }}"
        description: "Connector {{ $labels.connector }} has high task failure rate"
    
    - alert: KafkaConnectWorkerDown
      expr: up{job="kafka-connect-service"} == 0
      for: 2m
      labels:
        severity: critical
        component: kafka-connect
      annotations:
        summary: "Kafka Connect worker is down"
        description: "Kafka Connect worker in {{ $labels.namespace }} is unreachable"
  
  - name: flink-alerts
    interval: 30s
    rules:
    - alert: FlinkJobFailed
      expr: flink_jobmanager_job_uptime == 0
      for: 1m
      labels:
        severity: critical
        component: flink
      annotations:
        summary: "Flink job {{ $labels.job_name }} failed"
        description: "Flink job {{ $labels.job_name }} has failed or restarted"
    
    - alert: FlinkHighBackpressure
      expr: flink_taskmanager_job_task_backPressuredTimeMsPerSecond > 500
      for: 5m
      labels:
        severity: warning
        component: flink
      annotations:
        summary: "High backpressure in Flink task"
        description: "Task {{ $labels.task_name }} experiencing high backpressure"
    
    - alert: FlinkCheckpointFailure
      expr: rate(flink_jobmanager_job_numberOfFailedCheckpoints[5m]) > 0.1
      for: 5m
      labels:
        severity: warning
        component: flink
      annotations:
        summary: "Flink checkpoint failures detected"
        description: "Job {{ $labels.job_name }} has failing checkpoints"
    
    - alert: FlinkHighRestartRate
      expr: rate(flink_jobmanager_job_numRestarts[10m]) > 0.5
      for: 10m
      labels:
        severity: critical
        component: flink
      annotations:
        summary: "Flink job {{ $labels.job_name }} restarting frequently"
        description: "Job has restarted multiple times in 10 minutes"
  
  - name: doris-alerts
    interval: 30s
    rules:
    - alert: DorisFENodeDown
      expr: up{job="doris-fe-service"} == 0
      for: 2m
      labels:
        severity: critical
        component: doris
      annotations:
        summary: "Doris FE node is down"
        description: "Doris Frontend node {{ $labels.instance }} is unreachable"
    
    - alert: DorisBENodeDown
      expr: up{job="doris-be-service"} == 0
      for: 2m
      labels:
        severity: critical
        component: doris
      annotations:
        summary: "Doris BE node is down"
        description: "Doris Backend node {{ $labels.instance }} is unreachable"
    
    - alert: DorisHighQueryLatency
      expr: histogram_quantile(0.95, rate(doris_fe_query_latency_ms_bucket[5m])) > 5000
      for: 5m
      labels:
        severity: warning
        component: doris
      annotations:
        summary: "High query latency in Doris"
        description: "95th percentile query latency is above 5 seconds"
    
    - alert: DorisHighDiskUsage
      expr: (doris_be_disk_used_bytes / doris_be_disk_total_bytes) > 0.85
      for: 10m
      labels:
        severity: warning
        component: doris
      annotations:
        summary: "High disk usage on Doris BE node"
        description: "BE node {{ $labels.instance }} disk usage above 85%"
    
    - alert: DorisLoadJobFailed
      expr: rate(doris_be_load_rows_failed[5m]) > 100
      for: 5m
      labels:
        severity: warning
        component: doris
      annotations:
        summary: "Doris data load failures detected"
        description: "High rate of failed load operations on {{ $labels.instance }}"
  
  - name: streaming-data-quality-alerts
    interval: 1m
    rules:
    - alert: StreamingDataDelayed
      expr: (time() - kafka_consumer_lag_seconds) > 300
      for: 5m
      labels:
        severity: warning
        component: streaming
      annotations:
        summary: "Streaming data delayed"
        description: "Consumer lag exceeds 5 minutes for topic {{ $labels.topic }}"
    
    - alert: HighStreamingErrorRate
      expr: rate(stream_processing_errors_total[5m]) > 10
      for: 5m
      labels:
        severity: critical
        component: streaming
      annotations:
        summary: "High error rate in streaming pipeline"
        description: "Streaming pipeline experiencing high error rate"
    
    - alert: NoStreamingDataReceived
      expr: rate(kafka_topic_partition_current_offset[5m]) == 0
      for: 10m
      labels:
        severity: warning
        component: streaming
      annotations:
        summary: "No data received in Kafka topic"
        description: "Topic {{ $labels.topic }} has not received data for 10 minutes"


