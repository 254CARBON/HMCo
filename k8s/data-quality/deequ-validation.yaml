# Apache Deequ Data Quality Framework
# Comprehensive validation for commodity data platform

---
# Spark Operator for running Deequ jobs
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-deequ-validator
  namespace: data-platform
  labels:
    app: spark-deequ
    component: data-quality
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-deequ
  template:
    metadata:
      labels:
        app: spark-deequ
        component: data-quality
    spec:
      containers:
      - name: spark-submit
        image: apache/spark:3.5.0-scala2.12-java11-python3-ubuntu
        resources:
          requests:
            cpu: "4000m"
            memory: "8Gi"
          limits:
            cpu: "8000m"
            memory: "16Gi"
        env:
        - name: SPARK_MASTER
          value: "local[*]"
        - name: SPARK_DRIVER_MEMORY
          value: "4g"
        - name: SPARK_EXECUTOR_MEMORY
          value: "8g"
        - name: AWS_ENDPOINT_URL
          value: "http://minio-service:9000"
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: minio-secret
              key: access-key
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: minio-secret
              key: secret-key
        - name: PYTHONUSERBASE
          value: "/tmp/python-packages"
        - name: PIP_CACHE_DIR
          value: "/tmp/pip-cache"
        volumeMounts:
        - name: deequ-scripts
          mountPath: /opt/spark/work-dir/scripts
        - name: validation-results
          mountPath: /opt/spark/validation-results
        command:
        - /bin/bash
        - -c
        - |
          set -e
          echo "Installing Deequ and dependencies..."
          
          # Set Python path to include user packages
          export PATH="/tmp/python-packages/bin:$PATH"
          export PYTHONPATH="/tmp/python-packages/lib/python3.10/site-packages:$PYTHONPATH"
          
          # Install packages to /tmp (writable directory)
          pip install --user --no-cache-dir pydeequ pyspark boto3 pyiceberg trino
          
          echo "Deequ Data Quality Validator is ready"
          echo "Installed packages location: /tmp/python-packages"
          echo "Run validation jobs via spark-submit"
          
          # Keep container running
          tail -f /dev/null
      volumes:
      - name: deequ-scripts
        configMap:
          name: deequ-validation-scripts
      - name: validation-results
        emptyDir:
          sizeLimit: 10Gi

---
# Deequ Validation Scripts
apiVersion: v1
kind: ConfigMap
metadata:
  name: deequ-validation-scripts
  namespace: data-platform
  labels:
    app: spark-deequ
    component: data-quality
data:
  # Energy Prices Validation
  validate_energy_prices.py: |
    #!/usr/bin/env python3
    """
    Deequ validation for energy prices data
    Validates completeness, accuracy, and consistency
    """
    from pydeequ.checks import Check, CheckLevel
    from pydeequ.verification import VerificationSuite, VerificationResult
    from pyspark.sql import SparkSession
    from datetime import datetime, timedelta
    import json
    
    # Initialize Spark
    spark = SparkSession.builder \
        .appName("Commodity Data Quality - Energy Prices") \
        .config("spark.jars.packages", "com.amazon.deequ:deequ:2.0.3-spark-3.4") \
        .getOrCreate()
    
    # Load data from Iceberg
    iceberg_catalog = "http://iceberg-rest-catalog:8181"
    df = spark.read \
        .format("iceberg") \
        .option("catalog-uri", iceberg_catalog) \
        .load("commodity_data.energy_prices")
    
    # Filter to recent data (last 7 days)
    seven_days_ago = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
    recent_df = df.filter(f"price_date >= '{seven_days_ago}'")
    
    print(f"Validating {recent_df.count()} energy price records...")
    
    # Define validation checks
    verification = VerificationSuite(spark) \
        .onData(recent_df) \
        .addCheck(
            Check(spark, CheckLevel.Error, "Energy Prices Integrity")
            .hasSize(lambda x: x >= 100)  # At least 100 records per week
            .isComplete("commodity")  # No null commodities
            .isComplete("price")  # No null prices
            .isComplete("price_date")  # No null dates
            .isUnique("commodity", "price_date", "location")  # No duplicates
            .isNonNegative("price")  # Prices must be positive
            .isContainedIn("commodity", ["crude_oil", "natural_gas", "electricity", "lng"])
            .hasMin("price", lambda x: x >= 0)  # Minimum price >= 0
            .hasMax("price", lambda x: x <= 10000)  # Maximum price <= $10,000
            .satisfies("price > 0 AND price < 10000", "price_validity")
        ) \
        .addCheck(
            Check(spark, CheckLevel.Warning, "Energy Prices Quality")
            .hasCompleteness("location", lambda x: x >= 0.95)  # 95% completeness
            .hasCompleteness("units", lambda x: x >= 0.90)
            .hasStandardDeviation("price", lambda x: x > 0)  # Some variance expected
        )
    
    # Run verification
    result = verification.run()
    
    # Parse results
    result_df = VerificationResult.checkResultsAsDataFrame(spark, result)
    result_df.show(truncate=False)
    
    # Save results to MinIO
    output_path = f"s3a://commodity-data/quality-reports/energy_prices_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    # Convert to JSON
    results_json = {
        "table": "energy_prices",
        "validation_time": datetime.now().isoformat(),
        "record_count": recent_df.count(),
        "status": result.status.value,
        "checks_passed": sum(1 for r in result.checkResults.values() if r.status.value == "Success"),
        "checks_total": len(result.checkResults),
        "violations": [
            {
                "check": check_name,
                "status": check_result.status.value,
                "constraint": check_result.constraint.toString()
            }
            for check_name, check_result in result.checkResults.items()
            if check_result.status.value != "Success"
        ]
    }
    
    print("\n=== Validation Results ===")
    print(json.dumps(results_json, indent=2))
    
    # Write to log for Prometheus scraping
    if results_json["status"] == "Success":
        print("quality_validation_success 1")
    else:
        print("quality_validation_success 0")
    
    print(f"quality_validation_checks_passed {results_json['checks_passed']}")
    print(f"quality_validation_checks_total {results_json['checks_total']}")
    print(f"quality_validation_record_count {results_json['record_count']}")
    
    spark.stop()

  # Economic Indicators Validation
  validate_economic_indicators.py: |
    #!/usr/bin/env python3
    """
    Deequ validation for economic indicators
    """
    from pydeequ.checks import Check, CheckLevel
    from pydeequ.verification import VerificationSuite
    from pyspark.sql import SparkSession
    from datetime import datetime, timedelta
    
    spark = SparkSession.builder \
        .appName("Data Quality - Economic Indicators") \
        .config("spark.jars.packages", "com.amazon.deequ:deequ:2.0.3-spark-3.4") \
        .getOrCreate()
    
    # Load economic indicators
    iceberg_catalog = "http://iceberg-rest-catalog:8181"
    df = spark.read \
        .format("iceberg") \
        .option("catalog-uri", iceberg_catalog) \
        .load("commodity_data.economic_indicators")
    
    thirty_days_ago = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
    recent_df = df.filter(f"observation_date >= '{thirty_days_ago}'")
    
    print(f"Validating {recent_df.count()} economic indicator records...")
    
    # Validation checks
    verification = VerificationSuite(spark) \
        .onData(recent_df) \
        .addCheck(
            Check(spark, CheckLevel.Error, "Economic Indicators Integrity")
            .hasSize(lambda x: x >= 50)  # At least 50 records per month
            .isComplete("indicator_code")
            .isComplete("observation_date")
            .isComplete("value")
            .isComplete("source")
            .isNonNegative("value")  # Most economic indicators are positive
            .isContainedIn("source", ["FRED", "WORLD_BANK", "IMF", "BLS"])
        ) \
        .addCheck(
            Check(spark, CheckLevel.Warning, "Economic Indicators Quality")
            .hasUniqueness(["indicator_code", "observation_date", "source"], lambda x: x >= 0.99)
            .hasCompleteness("units", lambda x: x >= 0.80)
        )
    
    result = verification.run()
    result_df = VerificationResult.checkResultsAsDataFrame(spark, result)
    result_df.show(truncate=False)
    
    # Metrics for Prometheus
    print(f"quality_validation_status{{table='economic_indicators'}} {1 if result.status.value == 'Success' else 0}")
    
    spark.stop()

  # Comprehensive Data Quality Report
  generate_quality_report.py: |
    #!/usr/bin/env python3
    """
    Generate comprehensive data quality report for all commodity tables
    """
    from pyspark.sql import SparkSession
    from pyspark.sql.functions import col, count, countDistinct, min, max, avg, stddev
    from datetime import datetime
    import json
    
    spark = SparkSession.builder \
        .appName("Commodity Data Quality Report") \
        .getOrCreate()
    
    iceberg_catalog = "http://iceberg-rest-catalog:8181"
    tables = ["energy_prices", "economic_indicators", "weather_forecasts"]
    
    report = {
        "generated_at": datetime.now().isoformat(),
        "tables": {}
    }
    
    for table_name in tables:
        print(f"\nAnalyzing {table_name}...")
        
        try:
            df = spark.read \
                .format("iceberg") \
                .option("catalog-uri", iceberg_catalog) \
                .load(f"commodity_data.{table_name}")
            
            # Compute statistics
            total_records = df.count()
            distinct_dates = df.select(countDistinct("ingestion_date")).collect()[0][0]
            
            # Null value analysis
            null_counts = {
                col_name: df.filter(col(col_name).isNull()).count()
                for col_name in df.columns
            }
            
            report["tables"][table_name] = {
                "total_records": total_records,
                "distinct_dates": distinct_dates,
                "null_value_rates": {
                    col_name: round(100 * count / total_records, 2)
                    for col_name, count in null_counts.items()
                },
                "completeness_score": round(100 * (1 - sum(null_counts.values()) / (total_records * len(df.columns))), 2)
            }
            
            print(f"  - Records: {total_records}")
            print(f"  - Completeness: {report['tables'][table_name]['completeness_score']}%")
        
        except Exception as e:
            print(f"  Error analyzing {table_name}: {e}")
            report["tables"][table_name] = {"error": str(e)}
    
    # Print report
    print("\n=== Data Quality Report ===")
    print(json.dumps(report, indent=2))
    
    # Export metrics for Prometheus
    for table_name, stats in report["tables"].items():
        if "completeness_score" in stats:
            print(f"data_quality_completeness{{table='{table_name}'}} {stats['completeness_score']}")
            print(f"data_quality_records{{table='{table_name}'}} {stats['total_records']}")
    
    spark.stop()

---
# CronJob for Daily Data Quality Validation
apiVersion: batch/v1
kind: CronJob
metadata:
  name: daily-data-quality-validation
  namespace: data-platform
  labels:
    app: data-quality
    component: validation
spec:
  schedule: "0 6 * * *"  # Run at 6 AM UTC daily
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: data-quality
        spec:
          restartPolicy: OnFailure
          containers:
          - name: deequ-validator
            image: apache/spark:3.5.0-scala2.12-java11-python3-ubuntu
            resources:
              requests:
                cpu: "2000m"
                memory: "4Gi"
              limits:
                cpu: "4000m"
                memory: "8Gi"
            env:
            - name: AWS_ENDPOINT_URL
              value: "http://minio-service:9000"
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: access-key
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: secret-key
            command:
            - /bin/bash
            - -c
            - |
              set -e
              echo "Starting data quality validation..."
              
              # Install dependencies
              pip install pydeequ boto3 pyiceberg trino-python-client
              
              # Run validation scripts
              cd /scripts
              
              echo "Validating energy prices..."
              python3 validate_energy_prices.py
              
              echo "Validating economic indicators..."
              python3 validate_economic_indicators.py
              
              echo "Generating quality report..."
              python3 generate_quality_report.py
              
              echo "Data quality validation complete!"
            volumeMounts:
            - name: scripts
              mountPath: /scripts
            - name: results
              mountPath: /results
          volumes:
          - name: scripts
            configMap:
              name: deequ-validation-scripts
          - name: results
            emptyDir: {}

---
# Data Quality Metrics Exporter
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-quality-exporter
  namespace: data-platform
  labels:
    app: data-quality-exporter
    component: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: data-quality-exporter
  template:
    metadata:
      labels:
        app: data-quality-exporter
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - name: exporter
        image: python:3.11-slim
        ports:
        - containerPort: 9090
          name: metrics
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
        env:
        - name: TRINO_HOST
          value: "trino-coordinator"
        - name: TRINO_PORT
          value: "8080"
        - name: METRICS_PORT
          value: "9090"
        volumeMounts:
        - name: exporter-script
          mountPath: /app
        command:
        - /bin/bash
        - -c
        - |
          set -e
          pip install --quiet trino prometheus-client
          cd /app
          python3 quality_metrics_exporter.py
      volumes:
      - name: exporter-script
        configMap:
          name: quality-metrics-exporter-script

---
# Quality Metrics Exporter Script
apiVersion: v1
kind: ConfigMap
metadata:
  name: quality-metrics-exporter-script
  namespace: data-platform
data:
  quality_metrics_exporter.py: |
    #!/usr/bin/env python3
    """
    Prometheus exporter for commodity data quality metrics
    """
    import time
    import os
    from prometheus_client import start_http_server, Gauge, Counter
    from trino.dbapi import connect
    from trino.auth import BasicAuthentication
    
    # Metrics
    data_completeness = Gauge('commodity_data_completeness_percent', 
                             'Data completeness percentage', ['table'])
    null_value_rate = Gauge('commodity_data_null_value_rate', 
                           'Null value rate by field', ['table', 'field'])
    record_count = Gauge('commodity_data_record_count', 
                        'Total record count', ['table'])
    duplicate_count = Gauge('commodity_data_duplicate_count', 
                           'Number of duplicate records', ['table'])
    last_ingestion = Gauge('commodity_data_last_ingestion_timestamp', 
                          'Unix timestamp of last ingestion', ['table'])
    quality_score = Gauge('commodity_data_quality_score', 
                         'Overall quality score (0-100)', ['table'])
    
    def get_trino_connection():
        """Create Trino connection"""
        return connect(
            host=os.getenv('TRINO_HOST', 'trino-coordinator'),
            port=int(os.getenv('TRINO_PORT', '8080')),
            user='quality_monitor',
            catalog='iceberg_catalog',
            schema='commodity_data'
        )
    
    def collect_metrics():
        """Collect data quality metrics from Trino"""
        try:
            conn = get_trino_connection()
            cursor = conn.cursor()
            
            # Check energy prices quality
            cursor.execute("""
                SELECT 
                    COUNT(*) as total,
                    COUNT(CASE WHEN price IS NULL THEN 1 END) as null_prices,
                    COUNT(CASE WHEN location IS NULL THEN 1 END) as null_locations,
                    COUNT(*) - COUNT(DISTINCT commodity || CAST(price_date AS VARCHAR) || location) as duplicates,
                    UNIX_TIMESTAMP(MAX(ingestion_time)) as last_ingestion,
                    100.0 * (1 - CAST(COUNT(CASE WHEN price IS NULL OR price < 0 OR price > 10000 THEN 1 END) AS DOUBLE) / COUNT(*)) as quality
                FROM energy_prices
                WHERE price_date >= CURRENT_DATE - INTERVAL '7' DAY
            """)
            
            row = cursor.fetchone()
            if row:
                total, null_prices, null_locations, dupes, last_ing, qual = row
                
                record_count.labels(table='energy_prices').set(total or 0)
                null_value_rate.labels(table='energy_prices', field='price').set(
                    (null_prices or 0) * 100.0 / (total or 1))
                null_value_rate.labels(table='energy_prices', field='location').set(
                    (null_locations or 0) * 100.0 / (total or 1))
                duplicate_count.labels(table='energy_prices').set(dupes or 0)
                last_ingestion.labels(table='energy_prices').set(last_ing or 0)
                quality_score.labels(table='energy_prices').set(qual or 0)
                
                completeness = 100.0 * (1 - ((null_prices or 0) + (null_locations or 0)) / (2 * (total or 1)))
                data_completeness.labels(table='energy_prices').set(completeness)
            
            # Similar queries for other tables...
            print(f"Metrics collected successfully at {time.strftime('%Y-%m-%d %H:%M:%S')}")
            
        except Exception as e:
            print(f"Error collecting metrics: {e}")
    
    if __name__ == "__main__":
        port = int(os.getenv('METRICS_PORT', '9090'))
        print(f"Starting Prometheus exporter on port {port}...")
        start_http_server(port)
        
        while True:
            collect_metrics()
            time.sleep(60)  # Collect metrics every minute

---
# ServiceMonitor for Prometheus scraping
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: data-quality-exporter
  namespace: monitoring
  labels:
    app: data-quality-exporter
    release: kube-prometheus-stack
spec:
  selector:
    matchLabels:
      app: data-quality-exporter
  namespaceSelector:
    matchNames:
    - data-platform
  endpoints:
  - port: metrics
    interval: 60s
    path: /metrics

---
# Service for Data Quality Exporter
apiVersion: v1
kind: Service
metadata:
  name: data-quality-exporter
  namespace: data-platform
  labels:
    app: data-quality-exporter
spec:
  selector:
    app: data-quality-exporter
  ports:
  - name: metrics
    port: 9090
    targetPort: 9090
  type: ClusterIP

